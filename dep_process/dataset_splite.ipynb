{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import re\n",
    "# from tqdm import tqdm  # 进度条\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import unicodedata\n",
    "import datetime\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import sacrebleu\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import pickle\n",
    "import torch_optimizer as optim\n",
    "# import adamod\n",
    "import os\n",
    "import shutil\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX_LENGTH： 100\n"
     ]
    }
   ],
   "source": [
    "print('dataset_splite.ipynb')\n",
    "\n",
    "MAX_LENGTH = int(sys.argv[1])  # MAX_LENGTH = 100\n",
    "print('MAX_LENGTH：', MAX_LENGTH)\n",
    "current_datasets_path = sys.argv[2] #'/home/chengkun/jupyter_projects/Magic-NLPer-main/data/en_zh/'\n",
    "print('current_datasets_path：', current_datasets_path)\n",
    "parallel_corpus = sys.argv[3] #'news_en_zh_shuffle_final.txt'\n",
    "print('parallel_corpus：', parallel_corpus)\n",
    "\n",
    "train_pairs_path = current_datasets_path + 'train_pairs'\n",
    "val_pairs_path = current_datasets_path + 'val_pairs'\n",
    "test_pairs_path = current_datasets_path + 'test_pairs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数据读取\n",
    "# 当你用read_csv读文件的时候，如果文本里包含英文双引号，直接读取会导致行数变少或是直接如下报错停止\n",
    "# 此时应该对read_csv设置参数控制csv中的引号常量，设定quoting=3或是quoting=csv.QUOTE_NONE”（注：用第二种要先导csv库）然后问题就解决了。\n",
    "\n",
    "data_df = pd.read_csv(current_datasets_path + parallel_corpus,  # 数据格式：英语\\t法语，注意我们的任务源语言是法语，目标语言是英语\n",
    "                      encoding='UTF-8', sep='\\t', header=None,quoting=3,\n",
    "                      names=['src', 'targ'], index_col=False)\n",
    "\n",
    "# print(data_df.shape)\n",
    "# print(data_df.values.shape)\n",
    "# print(data_df.values[0])\n",
    "# print(data_df.values[0].shape)\n",
    "# data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "\n",
    "# 规范化字符串\n",
    "def normalizeString(s):\n",
    "    # print(s) # list  ['Go.']\n",
    "    # s = s[0]\n",
    "    s = s.lower().strip()\n",
    "    #s = unicodeToAscii(s)\n",
    "    #s = re.sub(r\"([.!?])\", r\" \\1\", s)  # \\1表示group(1)即第一个匹配到的 即匹配到'.'或者'!'或者'?'后，一律替换成'空格.'或者'空格!'或者'空格？'\n",
    "    #s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)  # 非字母以及非.!?的其他任何字符 一律被替换成空格\n",
    "    s = re.sub(r'[\\s]+', \" \", s)  # 将出现的多个空格，都使用一个空格代替。例如：w='abc  1   23  1' 处理后：w='abc 1 23 1'\n",
    "    return s\n",
    "\n",
    "\n",
    "# print(normalizeString('Va !'))\n",
    "# print(normalizeString('Go.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairs num= 171915\n"
     ]
    }
   ],
   "source": [
    "pairs = [[normalizeString(s) for s in line] for line in data_df.values]\n",
    "\n",
    "print('pairs num=', len(pairs))\n",
    "# print(pairs[0])\n",
    "# print(pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过过滤后平行语料数目为： 171915\n"
     ]
    }
   ],
   "source": [
    "# 文件是英译法，我们实现的是法译英，所以进行了reverse，所以pair[1]是英语\n",
    "# 为了快速训练，仅保留“我是”“你是”“他是”等简单句子，并且删除原始文本长度大于10个标记的样本\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    # 过滤，并交换句子顺序，得到法英句子对（之前是英法句子对）\n",
    "    return [[pair[0], pair[1]] for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "pairs = filterPairs(pairs)\n",
    "\n",
    "print('经过过滤后平行语料数目为：', len(pairs))\n",
    "# print(pairs[0])\n",
    "# print(random.choice(pairs))\n",
    "# print(np.array(pairs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 划分数据集：训练集和验证集\n",
    "##蒙汉50w 0.020 0.020\n",
    "##英汉\n",
    "train_test, val_pairs = train_test_split(pairs, test_size=0.030, random_state=1234)\n",
    "train_pairs, test_pairs = train_test_split(train_test, test_size=0.030, random_state=1234)\n",
    "\n",
    "# print('训练集句子数目：', len(train_pairs))\n",
    "# print('验证集句子数目：', len(val_pairs))\n",
    "# print('测试集句子数目：', len(test_pairs))\n",
    "# print(test_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_pairs_path,'wb') as f:\n",
    "    pickle.dump(train_pairs, f)\n",
    "    f.close()\n",
    "\n",
    "with open(val_pairs_path,'wb') as f:\n",
    "    pickle.dump(val_pairs, f)\n",
    "    f.close()\n",
    "\n",
    "with open(test_pairs_path,'wb') as f:\n",
    "    pickle.dump(test_pairs, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集句子数目： 161754\n",
      "验证集句子数目： 5158\n",
      "测试集句子数目： 5003\n"
     ]
    }
   ],
   "source": [
    "print('训练集句子数目：', len(train_pairs))\n",
    "print('验证集句子数目：', len(val_pairs))\n",
    "print('测试集句子数目：', len(test_pairs))\n",
    "print('运行结束')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'/home/chengkun/jupyter_projects/Magic-NLPer-main/data/data_sets/en_zh/train_pairs','rb') as f:\n",
    "#     train_pairs = pickle.load(f)\n",
    "#     f.close()\n",
    "\n",
    "# with open(r'/home/chengkun/jupyter_projects/Magic-NLPer-main/data/data_sets/en_zh/val_pairs','rb') as f:\n",
    "#     val_pairs = pickle.load(f)\n",
    "#     f.close()\n",
    "\n",
    "# with open(r'/home/chengkun/jupyter_projects/Magic-NLPer-main/data/data_sets/en_zh/test_pairs','rb') as f:\n",
    "#     test_pairs = pickle.load(f)\n",
    "#     f.close()\n",
    "\n",
    "# print('训练集句子数目：', len(train_pairs))\n",
    "# print('验证集句子数目：', len(val_pairs))\n",
    "# print('测试集句子数目：', len(test_pairs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
